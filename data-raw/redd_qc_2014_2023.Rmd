---
title: "feather river redd data exploration"
date: "2024-08-27"
output: 
  html_document:
    theme: flatly
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)

library(tidyverse)
library(lubridate)
library(googleCloudStorageR)
library(ggplot2)
library(scales)
library(dplyr)
library(leaflet)
library(RColorBrewer)
library(viridis)
library(readxl)
library(janitor)
library(sf)
library(openxlsx)
library(readxl)
```

Goal of this document is to review the Feather River redd data and understand the following:

- what data are collected?
- what is the quality of the data?
- what are the data limitations?
- how are these data useful to Science Plan hypotheses?

## Relevant Science Plan hypotheses

1. Spawning habitat acreage

- **From Science Plan:** "The metric for this hypothesis will be the acreage of spawning habitat with suitable water depths and velocities, and sizes of spawning gravel. Spawning habitat criteria, including depth, velocity, and target spawning substrate size will be defined in the specific VA action science and monitoring plan and associated design documents. The suitable gravel size for spawning habitat will be a range and distribution of spawning substrate sizes specific to the spawning population and hydrogeomorphic conditions in each tributary."

- **Ideas:** This hypothesis was set up to use depth and velocity criteria to map spawning habitat acreage and compare to existing habitat. We could map spawning habitat based on redd locations over time. We would need latitude and longitude of all redds observed.

2. Salmon redd density (this is the most relevant hypothesis)

- **From Science Plan:** "The metric for this hypothesis will be the number of Chinook salmon redds per unit area in habitat enhancement project areas, while also accounting for the potential for redd superimposition.  The baseline for this hypothesis will be the redd density and superimposition rate at habitat enhancement locations compared to adjacent areas within the same reach, measured concurrently along with water quality criteria. In systems where redd mapping has been conducted consistently at both project locations and adjacent, non-enhanced locations, historical data can also be leveraged to examine trends and changes in redd density after the enhancement action."

- **Ideas:** This is the number of redds per unit area. We would need a count of redds and some sort of delineation of the area where redds are occurring (this could be latitude/longitude of redd or river mile/reach surveyed, assuming whole area is surveyed)

3. Natural origin adult Chinook salmon population estimates by tributary, and trend in abundance (harvest plus escapement)  

- **From Science Plan:** "The metric for this hypothesis will be annual natural-origin adult Chinook salmon cohort replacement rates and trends over multiple years (e.g., > 3 years) over the period of VA implementation.   The baseline for this hypothesis will be the annual natural-origin adult Chinook salmon cohort replacement rate trends during the period associated with the Anadromous Fish Restoration Program Doubling Goal (years 1967-1991). A secondary baseline, to reflect recent conditions and population numbers, will be annual adult Chinook salmon cohort replacement rates and trends for natural-origin fall run Chinook salmon since 2010."

- **Ideas:** We would need high quality redd data in order to estimate adult population

*Contact*

These data were originally acquired from Chris Cook

*Timeframe*

- 2017-2023 
- Longitude and latitude data: #TODO add info

### Data quality

#TODO add info

```{r, include=FALSE, warning=FALSE}
redd_2014_raw <- readxl::read_excel(here::here("data-raw", "2014-2023 Chinook Redd Survey Data", "2014_Chinook_Redd_Survey_Data.xlsx")) |> 
  clean_names() |> 
  slice(-1912) |>  #removing the totals column
  glimpse()


redd_2014 <- redd_2014_raw |> 
  mutate(date = if_else(date == "10/1/2014", as.Date(date, format = "%m/%d/%Y"), convertToDate(date))) |> 
  rename(number_redds = number_of_redds) |> 
  glimpse()


redd_2015 <- readxl::read_xlsx(here::here("data-raw","2014-2023 Chinook Redd Survey Data","2015_Chinook_Redd_Survey_Data.xlsx"), range = cell_rows(1:2353)) |> 
  clean_names() |> 
  rename(number_redds = number_of_redds) |> 
  glimpse()

redd_2016 <- readxl::read_xlsx(here::here("data-raw","2014-2023 Chinook Redd Survey Data","2016_Chinook_Redd_Survey_Data.xlsx"), range = cell_rows(1:1571)) |> 
  clean_names() |> 
  rename(number_redds = number_of_redds) |> 
  glimpse()

redd_2017 <- readxl::read_xlsx(here::here("data-raw","2014-2023 Chinook Redd Survey Data","2017_Chinook_Redd_Survey_Data.xlsx"), range = cell_rows(1:2718)) |> 
  clean_names() |> 
  glimpse()

redd_2018 <- readxl::read_xlsx(here::here("data-raw","2014-2023 Chinook Redd Survey Data","2018_Chinook_Redd_Survey_Data.xlsx"), range = cell_rows(1:4170)) |> 
  clean_names() |> 
  glimpse()

redd_2019 <- readxl::read_xlsx(here::here("data-raw","2014-2023 Chinook Redd Survey Data","2019_Chinook_Redd_Survey_Data.xlsx"), range = cell_rows(1:5049)) |> 
  clean_names() |> 
  glimpse()

redd_2020 <- readxl::read_xlsx(here::here("data-raw","2014-2023 Chinook Redd Survey Data","2020_Chinook_Redd_Survey_Data.xlsx"), range = cell_rows(1:5432)) |> 
  clean_names() |> 
  rename(longitude_m_e = longitude_n_e) |> 
  glimpse()

redd_2021 <- readxl::read_xlsx(here::here("data-raw","2014-2023 Chinook Redd Survey Data","2021_Chinook_Redd_Survey_Data.xlsx"), range = cell_rows(1:2595)) |> 
  clean_names() |> 
  mutate(type = ifelse(type == "P", "p", type)) |> 
  glimpse()

redd_2022 <- readxl::read_xlsx(here::here("data-raw","2014-2023 Chinook Redd Survey Data","2022_Chinook_Redd_Survey_Data.xlsx"), range = cell_rows(1:3762)) |> 
  clean_names() |> 
  glimpse()
```


```{r, include=FALSE, warning=FALSE}
# 2023 data is formatted a bit different. Cleaning format here


redd_2023_week1 <- readxl::read_xlsx(here::here("data-raw","2014-2023 Chinook Redd Survey Data","2023_Chinook_Redd_Survey_Data.xlsx")) |>
  clean_names() |> 
  mutate(date =  mdy_hm(date_time),
         survey_wk = str_extract(x2, "\\d+-\\d+"),
         location = riffle_name,
         file_number = NA,
         type = NA,
         number_redds = number_of_fish_on_redd,
         number_salmon = NA,
         latitude_m_n = latitude_wgs_84,
         longitude_m_e = longitude_wgs_84,
         depth_m  = water_depth_m,
         pot_depth_m = NA,
         velocity_m_s = as.numeric(velocity_m_sec),
         percent_fines = as.numeric(percent_sand_0_0625_2mm), #should we also include % Silt <0.062mm
         percent_small = as.numeric(percent_gravel_2_64mm),
         percent_med = as.numeric(percent_pebble_64_128),
         percent_large = as.numeric(percent_cobble_128_256mm),
         percent_boulder = as.numeric(percent_boulder_256mm)) |> 
  select(date, survey_wk, location, file_number, type, number_redds, number_salmon, latitude_m_n, longitude_m_e, depth_m, pot_depth_m, velocity_m_s, percent_fines, percent_small, percent_med, percent_large, percent_boulder, redd_width_m, redd_length_m) |> 
  glimpse()

redd_2023_week2 <- readxl::read_xlsx(here::here("data-raw","2014-2023 Chinook Redd Survey Data","2023_Chinook_Redd_Survey_Data.xlsx"), sheet = 2)|>
  clean_names()|> 
  mutate(date =  mdy_hm(date_time),
         survey_wk = str_extract(x2, "\\d+-\\d+"),
         location = riffle_name,
         file_number = NA,
         type = NA,
         number_redds = number_of_fish_on_redd,
         number_salmon = NA,
         latitude_m_n = latitude_wgs_84,
         longitude_m_e = longitude_wgs_84,
         depth_m  = water_depth_m,
         pot_depth_m = NA,
         velocity_m_s = as.numeric(velocity_m_sec),
         percent_fines = as.numeric(percent_sand_0_0625_2mm), #should we also include % Silt <0.062mm
         percent_small = as.numeric(percent_gravel_2_64mm),
         percent_med = as.numeric(percent_pebble_64_128),
         percent_large = as.numeric(percent_cobble_128_256mm),
         percent_boulder = as.numeric(percent_boulder_256mm)) |> 
  select(date, survey_wk, location, file_number, type, number_redds, number_salmon, latitude_m_n, longitude_m_e, depth_m, pot_depth_m, velocity_m_s, percent_fines, percent_small, percent_med, percent_large, percent_boulder, redd_width_m, redd_length_m) |> 
  glimpse()

redd_2023_week3 <- readxl::read_xlsx(here::here("data-raw","2014-2023 Chinook Redd Survey Data","2023_Chinook_Redd_Survey_Data.xlsx"), sheet = 3)|>
  clean_names()|> 
  mutate(date =  mdy_hm(date_time),
         survey_wk = str_extract(x2, "\\d+-\\d+"),
         location = riffle_name,
         file_number = NA,
         type = NA,
         number_redds = number_of_fish_on_redd,
         number_salmon = NA,
         latitude_m_n = latitude_wgs_84,
         longitude_m_e = longitude_wgs_84,
         depth_m  = water_depth_m,
         pot_depth_m = NA,
         velocity_m_s = as.numeric(velocity_m_sec),
         percent_fines = as.numeric(percent_sand_0_0625_2mm), #should we also include % Silt <0.062mm
         percent_small = as.numeric(percent_gravel_2_64mm),
         percent_med = as.numeric(percent_pebble_64_128),
         percent_large = as.numeric(percent_cobble_128_256mm),
         percent_boulder = as.numeric(percent_boulder_256mm)) |> 
  select(date, survey_wk, location, file_number, type, number_redds, number_salmon, latitude_m_n, longitude_m_e, depth_m, pot_depth_m, velocity_m_s, percent_fines, percent_small, percent_med, percent_large, percent_boulder, redd_width_m, redd_length_m) |> 
  glimpse()

redd_2023_week4 <- readxl::read_xlsx(here::here("data-raw","2014-2023 Chinook Redd Survey Data","2023_Chinook_Redd_Survey_Data.xlsx"), sheet = 4)|>
  clean_names()|> 
  mutate(date =  mdy_hm(date_time),
         survey_wk = str_extract(x2, "\\d+-\\d+"),
         location = riffle_name,
         file_number = NA,
         type = NA,
         number_redds = number_of_fish_on_redd,
         number_salmon = NA,
         latitude_m_n = latitude_wgs_84,
         longitude_m_e = longitude_wgs_84,
         depth_m  = water_depth_m,
         pot_depth_m = NA,
         velocity_m_s = as.numeric(velocity_m_sec),
         percent_fines = as.numeric(percent_sand_0_0625_2mm), #should we also include % Silt <0.062mm
         percent_small = as.numeric(percent_gravel_2_64mm),
         percent_med = as.numeric(percent_pebble_64_128),
         percent_large = as.numeric(percent_cobble_128_256mm),
         percent_boulder = as.numeric(percent_boulder_256mm)) |> 
  select(date, survey_wk, location, file_number, type, number_redds, number_salmon, latitude_m_n, longitude_m_e, depth_m, pot_depth_m, velocity_m_s, percent_fines, percent_small, percent_med, percent_large, percent_boulder, redd_width_m, redd_length_m) |> 
  glimpse()

redd_2023_week5 <- readxl::read_xlsx(here::here("data-raw","2014-2023 Chinook Redd Survey Data","2023_Chinook_Redd_Survey_Data.xlsx"), sheet = 5)|>
  clean_names()|> 
  mutate(date =  mdy_hm(date_time),
         survey_wk = str_extract(x2, "\\d+-\\d+"),
         location = riffle_name,
         file_number = NA,
         type = NA,
         number_redds = number_of_fish_on_redd,
         number_salmon = NA,
         latitude_m_n = latitude_wgs_84,
         longitude_m_e = longitude_wgs_84,
         depth_m  = water_depth_m,
         pot_depth_m = NA,
         velocity_m_s = as.numeric(velocity_m_sec),
         percent_fines = as.numeric(percent_sand_0_0625_2mm), #should we also include % Silt <0.062mm
         percent_small = as.numeric(percent_gravel_2_64mm),
         percent_med = as.numeric(percent_pebble_64_128),
         percent_large = as.numeric(percent_cobble_128_256mm),
         percent_boulder = as.numeric(percent_boulder_256mm)) |> 
  select(date, survey_wk, location, file_number, type, number_redds, number_salmon, latitude_m_n, longitude_m_e, depth_m, pot_depth_m, velocity_m_s, percent_fines, percent_small, percent_med, percent_large, percent_boulder, redd_width_m, redd_length_m) |> 
  glimpse()

redd_2023_week6 <- readxl::read_xlsx(here::here("data-raw","2014-2023 Chinook Redd Survey Data","2023_Chinook_Redd_Survey_Data.xlsx"), sheet = 6)|>
  clean_names()|> 
  mutate(date =  mdy_hm(date_time),
         survey_wk = str_extract(x2, "\\d+-\\d+"),
         location = riffle_name,
         file_number = NA,
         type = NA,
         number_redds = number_of_fish_on_redd,
         number_salmon = NA,
         latitude_m_n = latitude_wgs_84,
         longitude_m_e = longitude_wgs_84,
         depth_m  = water_depth_m,
         pot_depth_m = NA,
         velocity_m_s = as.numeric(velocity_m_sec),
         percent_fines = as.numeric(percent_sand_0_0625_2mm), #should we also include % Silt <0.062mm
         percent_small = as.numeric(percent_gravel_2_64mm),
         percent_med = as.numeric(percent_pebble_64_128),
         percent_large = as.numeric(percent_cobble_128_256mm),
         percent_boulder = as.numeric(percent_boulder_256mm)) |> 
  select(date, survey_wk, location, file_number, type, number_redds, number_salmon, latitude_m_n, longitude_m_e, depth_m, pot_depth_m, velocity_m_s, percent_fines, percent_small, percent_med, percent_large, percent_boulder, redd_width_m, redd_length_m) |> 
  glimpse()

redd_2023_week7 <- readxl::read_xlsx(here::here("data-raw","2014-2023 Chinook Redd Survey Data","2023_Chinook_Redd_Survey_Data.xlsx"), sheet = 7)|>
  clean_names()|> 
  mutate(date =  mdy_hm(date_time),
         survey_wk = str_extract(workflow_level, "\\d+-\\d+"),
         location = riffle_name,
         file_number = NA,
         type = NA,
         number_redds = number_of_fish_on_redd,
         number_salmon = NA,
         latitude_m_n = latitude_wgs_84,
         longitude_m_e = longitude_wgs_84,
         depth_m  = water_depth_m,
         pot_depth_m = NA,
         velocity_m_s = as.numeric(velocity_m_sec),
         percent_fines = as.numeric(percent_sand_0_0625_2mm), #should we also include % Silt <0.062mm
         percent_small = as.numeric(percent_gravel_2_64mm),
         percent_med = as.numeric(percent_pebble_64_128),
         percent_large = as.numeric(percent_cobble_128_256mm),
         percent_boulder = as.numeric(percent_boulder_256mm)) |> 
  select(date, survey_wk, location, file_number, type, number_redds, number_salmon, latitude_m_n, longitude_m_e, depth_m, pot_depth_m, velocity_m_s, percent_fines, percent_small, percent_med, percent_large, percent_boulder, redd_width_m, redd_length_m) |> 
  glimpse()

redd_2023_week8 <- readxl::read_xlsx(here::here("data-raw","2014-2023 Chinook Redd Survey Data","2023_Chinook_Redd_Survey_Data.xlsx"), sheet = 8)|>
  clean_names()|> 
  mutate(date =  mdy_hm(date_time),
         survey_wk = str_extract(x2, "\\d+-\\d+"),
         location = riffle_name,
         file_number = NA,
         type = NA,
         number_redds = number_of_fish_on_redd,
         number_salmon = NA,
         latitude_m_n = latitude_wgs_84,
         longitude_m_e = longitude_wgs_84,
         depth_m  = water_depth_m,
         pot_depth_m = NA,
         velocity_m_s = as.numeric(velocity_m_sec),
         percent_fines = as.numeric(percent_sand_0_0625_2mm), #should we also include % Silt <0.062mm
         percent_small = as.numeric(percent_gravel_2_64mm),
         percent_med = as.numeric(percent_pebble_64_128),
         percent_large = as.numeric(percent_cobble_128_256mm),
         percent_boulder = as.numeric(percent_boulder_256mm)) |> 
  select(date, survey_wk, location, file_number, type, number_redds, number_salmon, latitude_m_n, longitude_m_e, depth_m, pot_depth_m, velocity_m_s, percent_fines, percent_small, percent_med, percent_large, percent_boulder, redd_width_m, redd_length_m) |> 
  glimpse()


redd_2023_week9 <- readxl::read_xlsx(here::here("data-raw","2014-2023 Chinook Redd Survey Data","2023_Chinook_Redd_Survey_Data.xlsx"), sheet = 9)|>
  clean_names()|> 
  mutate(date =  mdy_hm(date_time),
         survey_wk = str_extract(x2, "\\d+-\\d+"),
         location = riffle_name,
         file_number = NA,
         type = NA,
         number_redds = number_of_fish_on_redd,
         number_salmon = NA,
         latitude_m_n = latitude_wgs_84,
         longitude_m_e = longitude_wgs_84,
         depth_m  = water_depth_m,
         pot_depth_m = NA,
         velocity_m_s = as.numeric(velocity_m_sec),
         percent_fines = as.numeric(percent_sand_0_0625_2mm), #should we also include % Silt <0.062mm
         percent_small = as.numeric(percent_gravel_2_64mm),
         percent_med = as.numeric(percent_pebble_64_128),
         percent_large = as.numeric(percent_cobble_128_256mm),
         percent_boulder = as.numeric(percent_boulder_256mm)) |> 
  select(date, survey_wk, location, file_number, type, number_redds, number_salmon, latitude_m_n, longitude_m_e, depth_m, pot_depth_m, velocity_m_s, percent_fines, percent_small, percent_med, percent_large, percent_boulder, redd_width_m, redd_length_m) |> 
  glimpse()

redd_2023_week11 <- readxl::read_xlsx(here::here("data-raw","2014-2023 Chinook Redd Survey Data","2023_Chinook_Redd_Survey_Data.xlsx"), sheet = 10)|>
  clean_names()|> 
  mutate(date =  mdy_hm(date_time),
         survey_wk = str_extract(x2, "\\d+-\\d+"),
         location = riffle_name,
         file_number = NA,
         type = as.character(NA),
         number_redds = number_of_fish_on_redd,
         number_salmon = NA,
         latitude_m_n = latitude_wgs_84,
         longitude_m_e = longitude_wgs_84,
         depth_m  = water_depth_m,
         pot_depth_m = NA,
         velocity_m_s = as.numeric(velocity_m_sec),
         percent_fines = as.numeric(percent_sand_0_0625_2mm), #should we also include % Silt <0.062mm
         percent_small = as.numeric(percent_gravel_2_64mm),
         percent_med = as.numeric(percent_pebble_64_128),
         percent_large = as.numeric(percent_cobble_128_256mm),
         percent_boulder = as.numeric(percent_boulder_256mm)) |> 
  select(date, survey_wk, location, file_number, type, number_redds, number_salmon, latitude_m_n, longitude_m_e, depth_m, pot_depth_m, velocity_m_s, percent_fines, percent_small, percent_med, percent_large, percent_boulder, redd_width_m, redd_length_m) |> 
  glimpse()
```


```{r}
redd_2023 <- bind_rows(redd_2023_week1, redd_2023_week2, redd_2023_week3, redd_2023_week4, redd_2023_week5, redd_2023_week6, redd_2023_week7, redd_2023_week8, redd_2023_week9, redd_2023_week11) |> 
  glimpse()
```

### Data questions

- 2023 data has a lot of missing number_redds
- Latitude/Longitude unit system is inconsistent. Up until 2013, coordinate system is UTM, years following are shown as "latitude mn / longitude me" (probably zone 10). [This is some information we have found about that coordinate system](https://gis.stackexchange.com/questions/111847/what-kind-of-coordinate-system-has-values-like-48569-800me-706602-032mn). Why were the coordinate systems different, and how can we convert from mn/me to UTM?
- 2023 data has some fields that arent on previous years: redd #, Elevation (ft), Accuracy (ft), Subsample,
Boat Point, Comment, User. Should we include those in the combined data?
- On 2023 data, there is some data that was not collected, that was previously included in past years;
file_number (unless it is the same than redd_number?), type, number_salmon, pot_depth_m, 
- 2023 data has 6 fields for types of soil (boulder, cobble, pebble, gravel, sand and silt), other years have 5 (fines, small, med, large). They were matched by size but % silt was left out for now. Should we include that column in combined data?  


All coordinates, except 2023, are on  mn me format, transforming to UTM here
#TODO continue to look into the lat/long that did not tranform
```{r}
combined_14_22 <- bind_rows(redd_2014, redd_2015, redd_2016, redd_2017, redd_2018, redd_2019, redd_2020, redd_2021, redd_2022) |> 
  glimpse()

redd_sf <- combined_14_22 |> 
  mutate(
    longitude_m_e = ifelse(is.na(longitude_m_e), 0, longitude_m_e),
    latitude_m_n = ifelse(is.na(latitude_m_n), 0, latitude_m_n)
  )
  
# Create an sf object with the correct UTM zone
sf_points <- st_as_sf(redd_sf, coords = c("longitude_m_e", "latitude_m_n"), crs = 32610)

# Transform to geographic coordinates (latitude/longitude)
geo_points <- st_transform(sf_points, crs = 4326)

# View the transformed coordinates
print(geo_points)

combined_14_22$longitude <- st_coordinates(geo_points)[, "X"]
combined_14_22$latitude <- st_coordinates(geo_points)[, "Y"]

# View the updated dataframe
head(combined_14_22)
```


Combining all years into one object

```{r}
combined_redd <- bind_rows(redd_2014, redd_2015, redd_2016, redd_2017, redd_2018, redd_2019, redd_2020, redd_2021, redd_2022, redd_2023) |> 
  glimpse()
```

```{r}
str(combined_redd)
```

### Data exploration {.tabset}

Exploring fields that have data consistently

#### date
 
```{r}
#date range
range(combined_redd$date, na.rm = TRUE)
```


#### location

  * Location clean up is needed. There are some names that appear less than 5 times. We could check if they correspond to another location name, and it is spelled differently

```{r}
#locations
table(combined_redd$location) #there are 88 unique location names

unique(combined_redd$location)
```

**Locations surveyed less than 5 times**

For locations that are being surveyed less than five times, we might want to verify if they belong to other location area names. Otherwise, these sites might not have enough data to reliably analyze over time.

```{r}
#plotting those locations that appear less than 5 times
combined_redd |> 
  group_by(location) |> 
  filter(n() < 5) |> 
  ungroup() |> 
  count(location) |> 
  ggplot(aes(x = reorder(location, n), y = n)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  geom_text(aes(label = n), hjust = -0.3, size = 3.5) +
  labs(title = "Count of Locations with Less Than 5 Observations",
       x = "Location",
       y = "Number of Data Records") +
  theme_minimal()

```

**Frequent locations and years surveyed**

```{r, warning=FALSE}
location_frequent <- combined_redd |> 
  mutate(year = year(date)) |> 
  select(location, year) |> 
  group_by(location, year) |> 
  distinct() |> 
  ungroup() |> 
  group_by(location) |> 
  tally() |> 
  filter(n > 5)

combined_redd |> 
  mutate(year = as.factor(year(date))) |> 
  select(location, year) |> 
  group_by(location, year) |> 
  distinct() |> 
  filter(location %in% location_frequent$location) |> 
  ggplot(aes(x = year, y = location, color = year)) +
  geom_point(size = 2, alpha = 0.7) +
  labs(title = "Distinct Locations by Year",
       x = "Year",
       y = "Year",
       color = "Location") +  
  scale_color_viridis_d() +  
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, size = 14),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_text(size = 12),
        axis.text = element_text(size = 8),
        legend.position = "none")
  
```


#### type

**Observations by type and date**

```{r, warning=FALSE}
#type
unique(combined_redd$type)

ggplot(combined_redd, aes(x = date, y = type, color = type)) +
  geom_point(size = 2, alpha = 0.7) +
  labs(title = "Types Over Time",
       x = "Date",
       y = "Type",
       color = "Type") +
   scale_color_viridis_d(na.value = "grey50") +  
  theme_minimal() +
# Use Viridis color scale
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, size = 14),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_text(size = 12),
        axis.text = element_text(size = 10))
```


**Count of observations by type**

- note that all 2023 data does not have a `type` field

```{r}
combined_redd |> 
  group_by(type) |> 
  summarise(n = n()) |> 
  ggplot(aes(x = type, y = n, fill = type)) +
  geom_bar(stat = "identity", color = "black") +
  geom_text(aes(label = n), vjust = -0.5, size = 3.5) +
  scale_fill_viridis_d() +  
  labs(title = "Count of Observations by Type",
       x = "Type",
       y = "Count") +
  theme_minimal() 
```

#### redd_count

**Redd counts by year**

```{r}
range(combined_redd$number_redds, na.rm = TRUE)

combined_redd <- combined_redd %>%
  mutate(date = as.Date(date))
```

```{r, warning=FALSE}
ggplot(combined_redd, aes(x = date, y = number_redds)) +
  geom_point() +
  facet_wrap(~year(date), scales = "free") +
  scale_x_date(labels = date_format("%b"), date_breaks = "1 month") +
  labs(title = "Redd Counts Over Time") +
  theme_minimal() +
  theme(
    strip.background = element_rect(fill = "lightgrey", color = "grey50"),
    plot.title = element_text(hjust = 0.5)
  )
```

Same plot than above but with date values aggregated - using geom_col()

```{r}
ggplot(combined_redd, aes(x = date, y = number_redds)) +
  geom_col() +
  facet_wrap(~year(date), scales = "free") +
  scale_x_date(labels = date_format("%b"), date_breaks = "1 month") +
  labs(title = "Redd Counts Over Time") +
  theme_minimal() +
  theme(
    strip.background = element_rect(fill = "lightgrey", color = "grey50"),
    plot.title = element_text(hjust = 0.5)
  )

```


```{r, include=FALSE}
#checking for the number_redds NA values 
sum(is.na(redd_2023$number_redds))

sum(is.na(redd_2023_week11$number_redds))

sum(is.na(redd_2023_week1$number_redds))

sum(is.na(redd_2023_week2$number_redds))

sum(is.na(redd_2023_week9$number_redds))

#2023 data has a lot of missing number_redds
```


#### salmon_count

**Salmon counts by year**

```{r, warning=FALSE}
range(combined_redd$number_salmon, na.rm = TRUE)

combined_redd |> 
  filter(is.na(date)==FALSE) |>  
  ggplot(aes(x = date, y = number_salmon)) + 
  geom_col() +
  facet_wrap(~year(date), scales = "free") +
  scale_x_date(labels = date_format("%b"), date_breaks = "1 month") +
  labs(title = "Salmon Counts Over Time") +  
  theme_minimal() +
  theme(
    strip.background = element_rect(fill = "lightgrey", color = "grey50"),
    plot.title = element_text(hjust = 0.5) 
  )
```

Latitude and longitude needs to be transformed to UTM
#TODO

```{r, include = F}
# # Filter out rows with NA in either latitude or longitude
# combined_redd_clean <- combined_redd |> 
#   filter(!is.na(longitude_m_e) & !is.na(latitude_m_n))
# 
# # Create an sf object from your data
# combined_redd_sf <- combined_redd_clean |> 
#   mutate(
#     longitude_m_e = ifelse(is.na(longitude_m_e), NA, longitude_m_e),
#     latitude_m_n = ifelse(is.na(latitude_m_n), NA, latitude_m_n)) |> 
#   st_as_sf(coords = c("longitude_m_e", "latitude_m_n"), crs = 4326)
# 
# # Transform to UTM (replace "32633" with the appropriate UTM EPSG code for your zone)
# combined_redd_utm <- st_transform(combined_redd_sf, crs = 32611)

```

	

```{r}
#TODO note to check velocity for the following record:
# 2020-11-18 9-3 Upper Hatchery Riffle 49 velocity is negative 
```

```{r}
#save clean data to data/
write_csv(combined_redd, "data/all_redd_data.csv")
```

